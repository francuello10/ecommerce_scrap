# Competitive Intelligence Engine â€” Project Documentation

> **Para AIs (Cursor, Antigravity, Copilot, etc.) y humanos.**
> Este archivo es el punto de entrada Ãºnico para entender el proyecto.
> LÃ©elo completo antes de tocar cualquier archivo.

---

## ğŸ¯ Â¿QuÃ© hace este proyecto?

Motor de **inteligencia competitiva para eCommerce**. Monitorea sitios web y newsletters de competidores, detecta cambios (nuevas promos, financiaciÃ³n, tech stack), y genera **briefs diarios** con alertas en Slack.

**Stack:** Python 3.12 Â· FastAPI Â· PostgreSQL 16 Â· Directus 11 Â· ARQ (Redis) Â· SQLAlchemy 2.0 Â· HTTPX Â· Playwright Â· imap-tools

---

## ğŸ“ Estructura del Proyecto

```
ecommerce_scrap/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py          # Settings (pydantic-settings). Lee el .env.
â”‚   â”‚   â”œâ”€â”€ database.py        # Engine async SQLAlchemy + Base + get_db()
â”‚   â”‚   â”œâ”€â”€ models.py          # TODOS los modelos ORM (23 tablas)
â”‚   â”‚   â””â”€â”€ notifications/
â”‚   â”‚       â””â”€â”€ slack.py       # Sender de alertas Slack (httpx async)
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py            # FastAPI app. Entry point: uvicorn src.api.main:app
â”‚   â””â”€â”€ workers/
â”‚       â””â”€â”€ web_monitor/       # Web scraping engine
â”‚           â”œâ”€â”€ models.py      # Dataclasses: ExtractionResult, PromoSignal, etc.
â”‚           â”œâ”€â”€ platform_detector.py  # Layer 1: heurÃ­sticas por regex (VTEX, Shopify...)
â”‚           â”œâ”€â”€ extractor_factory.py  # Router: instancia el extractor correcto
â”‚           â””â”€â”€ extractors/
â”‚               â”œâ”€â”€ base.py          # BaseExtractor (abstract)
â”‚               â”œâ”€â”€ vtex.py          # VTEX IO extractor stub
â”‚               â”œâ”€â”€ shopify.py       # Shopify extractor stub
â”‚               â”œâ”€â”€ generic_html.py  # Fallback (BS4)
â”‚               â””â”€â”€ ...             # magento, tiendanube, woocommerce, prestashop
â”œâ”€â”€ alembic/                   # Migraciones de DB
â”‚   â”œâ”€â”€ env.py                 # Config de Alembic (usa PYTHONPATH=src)
â”‚   â””â”€â”€ versions/              # Archivos de migraciÃ³n generados
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ seed_tiers.py          # Inserta BASIC/PROFESSIONAL/ENTERPRISE en DB
â”‚   â””â”€â”€ _test_*.py             # Scripts de prueba temporales (se borran)
â”œâ”€â”€ docs/                      # DocumentaciÃ³n arquitectÃ³nica (ver abajo)
â”œâ”€â”€ tests/                     # Tests unitarios e integraciÃ³n
â”œâ”€â”€ docker-compose.yml         # Postgres 5433 + Redis 6379 + Directus 8055
â”œâ”€â”€ .env                       # Variables de entorno (NO commitear)
â”œâ”€â”€ .env.example               # Template del .env (sÃ­ commitear)
â”œâ”€â”€ pyproject.toml             # Dependencias (uv)
â””â”€â”€ Makefile                   # Shortcuts: make up, make db-upgrade, etc.
```

---

## âš¡ Setup RÃ¡pido (Primera vez)

```bash
# 1. Clonar y entrar al directorio
cd ecommerce_scrap

# 2. Copiar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales reales

# 3. Instalar dependencias
make install

# 4. Levantar infraestructura (Postgres, Redis, Directus)
make up

# 5. Aplicar migraciones
make db-upgrade

# 6. Insertar planes de suscripciÃ³n
make db-seed

# 7. Levantar la API
make api
```

**Puertos locales:**
| Servicio | Puerto |
|:---|:---|
| FastAPI | http://localhost:8000 |
| Directus | http://localhost:8055 |
| PostgreSQL | localhost:5433 |
| Redis | localhost:6379 |

**Directus login:** `admin@intel.local` / `admin_dev_2026`

---

## ğŸ—ºï¸ DocumentaciÃ³n ArquitectÃ³nica (`docs/`)

| Archivo | Contenido |
|:---|:---|
| `01_architecture.md` | Stack, principios de diseÃ±o |
| `02_database_schema.md` | Modelo de datos completo (23 tablas) |
| `03_workflows.md` | Flujos de los 6 workers/crons |
| `04_legacy_rescue_plan.md` | Lo que se rescatÃ³ del proyecto Go legacy |
| `05_stack_versions.md` | Versiones exactas de todas las librerÃ­as |
| `06_product_vision_cmo.md` | VisiÃ³n de producto / CMO |
| `07_tech_fingerprinting.md` | Estrategia de detecciÃ³n de stack tecnolÃ³gico |
| `08_pluggable_extractors.md` | Strategy Pattern para extractors por plataforma |
| `09_operational_flow.md` | Flujo completo: onboarding â†’ brief diario |
| `10_saas_business_model.md` | Multi-tenant, feature flags, upsell flow |

---

## ğŸ—„ï¸ Base de Datos â€” Tablas Clave

### SaaS / Multi-Tenant
- `subscription_tier` â€” Planes: BASIC ($49), PROFESSIONAL ($149), ENTERPRISE ($499). **Editables desde Directus.**
- `client` â€” Agencias/marcas clientes. Vinculadas a un tier.
- `client_competitor` â€” N:N entre client y competitor. `is_baseline=True` = "esta es MI empresa". `history_access_start_date` = llave del upsell histÃ³rico.

### ConfiguraciÃ³n (editables en Directus)
- `competitor` â€” **Global**. No pertenece a ningÃºn cliente. `domain` es UNIQUE.
- `monitored_page` â€” URLs a monitorear por competidor. Auto-descubiertas del header/footer.
- `newsletter_account` â€” Casilla IMAP de monitoreo (`newsbriefai.dev@gmail.com`).
- `newsletter_subscription` â€” Estado de suscripciÃ³n al newsletter de cada competidor.

### Operativas (solo lectura en Directus)
- `page_snapshot` â€” HTML crudo capturado. Append-only.
- `detected_signal` â€” SeÃ±al extraÃ­da (promo, cuota, envÃ­o gratis, CTA).
- `change_event` â€” Cambio detectado entre dos snapshots. Si `severity=CRITICAL` â†’ alerta Slack.
- `daily_brief` / `weekly_brief` â€” Briefs generados.

### Tech Fingerprinting
- `competitor_tech_profile` â€” Stack actual del competidor (1:1). `is_valid=False` â†’ recalibrar.
- `tech_profile_history` â€” Historial de cambios de stack (1:N, append-only).

---

## ğŸ¤– Workers / Jobs Principales

| Worker | Trigger | Feature Flag |
|:---|:---|:---|
| `competitor_onboarding` | Al crear competidor | Siempre |
| `web_monitor` | Cron (1x/3x/6x dÃ­a segÃºn tier) | Siempre |
| `newsletter_monitor` (IMAP) | Cron cada 15 min | `can_track_newsletters` |
| `tech_fingerprint` | Cron semanal (domingos 3AM) | `can_track_tech_stack` |
| `diff_engine` | Cascada post-scraping | Siempre |
| `briefing` | Cron diario 8:30AM | Siempre |

**Regla clave:** El orquestador **verifica los feature flags del tier del cliente antes de encolar** tareas costosas (Playwright, wappalyzer). Sin el flag â†’ no se encola.

---

## ğŸ”‘ Variables de Entorno Importantes

```bash
DATABASE_URL=postgresql+asyncpg://intel:intel_dev_2026@localhost:5433/competitive_intel
REDIS_URL=redis://localhost:6379/0
GEMINI_API_KEY=...          # Para generar briefs con IA
EMAIL_SERVER_USER=newsbriefai.dev@gmail.com
EMAIL_SERVER_PASSWORD=...   # Gmail App Password
SLACK_WEBHOOK_URL=...       # Para alertas en tiempo real
```

---

## ğŸ› ï¸ Comandos Make

```bash
make help          # Ver todos los comandos disponibles
make up            # Levantar Docker (Postgres + Redis + Directus)
make down          # Apagar Docker
make install       # Instalar dependencias con uv
make api           # Levantar FastAPI (dev mode con hot-reload)
make worker        # Levantar ARQ worker
make db-upgrade    # Aplicar migraciones
make db-migrate    # Crear nueva migraciÃ³n (pide descripciÃ³n)
make db-seed       # Insertar planes de suscripciÃ³n iniciales
make test          # Correr tests
make lint          # Chequear cÃ³digo con Ruff
make format        # Formatear cÃ³digo
```

---

## ğŸ—ï¸ GuÃ­a para Agregar CÃ³digo Nuevo

### Agregar un nuevo worker
1. Crear `src/workers/<nombre>/worker.py`
2. Definir la funciÃ³n async como job ARQ
3. Registrarlo en `src/workers/worker_settings.py`
4. Agregar el feature flag correspondiente en `SubscriptionTier`

### Agregar un nuevo extractor de plataforma
1. Crear `src/workers/web_monitor/extractors/<plataforma>.py`
2. Heredar de `BaseExtractor`
3. Implementar los mÃ©todos abstractos
4. Registrarlo en `ExtractorFactory.__platform_map`
5. Agregar la heurÃ­stica en `PlatformDetector`

### Agregar una nueva tabla
1. Definir el modelo en `src/core/models.py`
2. `make db-migrate` (pide descripciÃ³n)
3. `make db-upgrade`
4. Directus auto-introspecciÃ³n verÃ¡ la nueva tabla

---

## ğŸ“® Convenciones de CÃ³digo

- **Tipado estricto:** Todo con type hints. Usar `from __future__ import annotations`.
- **Async everywhere:** Funciones de DB y HTTP siempre async.
- **ORM solo para queries simples.** Queries complejas â†’ `select()` con SQLAlchemy Core.
- **Sin lÃ³gica en modelos.** Los modelos son DTOs. La lÃ³gica va en servicios/workers.
- **Fail-fast en config:** Si falta una variable de entorno requerida, el sistema falla al iniciar.
- **Formatter:** Ruff (`make format`). Line length: 100.
